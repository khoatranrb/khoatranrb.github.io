##### 2.1 Mô hình Học thống kê

* **Input:**

  * *Miền giá trị đầu vào:* Một tập $X$ bất kỳ, tập các đối tượng mà ta muốn gán nhãn.
  * *Miền giá trị nhãn:* $Y$, gồm hai lớp, thường là $\{0,1\}$ hoặc $\{-1,+1\}$​.
  * *Dữ liệu huấn luyện:* $S=\{(x_1,y_1)...(x_m,y_m)\}$ là tập hữu hạn các dữ liệu trên miền $X\times Y$.

* **Output:** Đầu ra là một hàm $h:X\to Y$. Hàm này có thể gọi là *hàm dự đoán*, một *giả thuyết* hoặc một *bộ phân lớp*. Chúng ta ký hiệu $A(S)$ cho: thuật toán học $A$ được huấn luyện từ tập dữ liệu $S$.

* **Mô hình sinh dữ liệu:** Chúng ta cùng giải thích về cách mà dữ liệu được sinh ra.

  * Đầu tiên, giả sử dữ liệu được lấy mẫu bởi phân bố xác suất $D$.
  * Tiếp theo, chúng ta giả định hàm gán nhãn *đúng* $f:X\to Y$.
  * Như vậy, từng cặp dữ liệu trong $S$ được lấy mẫu theo $D$ và gán nhãn bởi $f$.

* **Đánh giá hàm dự đoán:** 

  * *Sai số của bộ phân lớp* là xác suất dự đoán sai trên dữ liệu được lấy ngẫu nhiên.

  * Định nghĩa sai số dự đoán của $h:X\to Y$:
    $$
    L_{D,f}(h)=P_{x\sim D}[h(x)\ne f(x)]
    $$

  * $L_{D,f}(h)$ còn được gọi là *lỗi thật*, *lỗi tổng quát* hoặc *rủi ro kỳ vọng*.

* **Nhiệm vụ của bộ học:**

  * Bộ học **không biết** về phân bố $D$ và hàm gán nhãn $f$. Nhiệm vụ của nó là từ tập huấn luyện $S$ tìm ra một giả thuyết $h$ tốt nhất có thể được theo nghĩa tối thiểu hóa rủi ro kỳ vọng $L_{D,f}(h)$.



##### Tham khảo:

​	[1] <a href='https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf'>Understanding machine learning-theory algorithms.</a>

​	[2] <a href='https://uetailab.com/index.php/2019/10/11/uml2-1-hoc-thong-ke/'>UML2.1 – Học thống kê | UET_AI_LAB.</a>

