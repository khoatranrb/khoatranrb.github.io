<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      
      Khoa Blog
      
    </title>
    <link rel="shortcut icon" type="image/x-icon" href="/assets/res/favicon.ico">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/materialize/0.99.0/css/materialize.min.css">
    <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="/assets/css/main.css">
    
    
    <link rel="stylesheet" href="/assets/css/page.css">
    
    
    
    <link rel="stylesheet" href="/assets/css/syntax.css">
    <link rel="alternate" title="Beta" href="http://khoablogs.github.io">
    <link rel="sitemap" type="application/xml" title="Sitemap" href="/sitemap.xml">
    <!-- Begin Jekyll SEO tag v2.6.1 -->
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Khoa Blog" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Science Blog!" />
<meta property="og:description" content="Science Blog!" />
<link rel="canonical" href="http://localhost:4000/MD/MLPR5" />
<meta property="og:url" content="http://localhost:4000/MD/MLPR5" />
<meta property="og:site_name" content="Khoa Blog" />
<meta name="google-site-verification" content="UA-96359860-1" />
<script type="application/ld+json">
{"@type":"WebPage","url":"http://localhost:4000/MD/MLPR5","headline":"Khoa Blog","description":"Science Blog!","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>
  <body>
    <header>
      <nav class="top-nav teal">
        <div class="nav-wrapper">
          <div class="container">
            <a class="page-title" href="/">Khoa Blog</a>
          </div>
        </div>
      </nav>
      <div class="container">
        <a href="#" data-activates="slide-out" class="button-collapse top-nav full hide-on-large-only">
          <i class="material-icons">menu</i>
        </a>
      </div>
      <ul id="slide-out" class="side-nav fixed">
        <li>
          <div class="userView">
            <div class="background"></div>
            <a href="https://github.com/khoatranrb" target="_blank"><img class="circle z-depth-2" src="/assets/res/user.png"></a>
            <span class="white-text name">Khoa Tran</span>
            <span class="white-text email">khoatranrb@gmail.com</span>
          </div>
        </li>
        <li><a class="waves-effect" href="/"><i class="material-icons">home</i>Home</a></li>
        <li><a class="waves-effect" href="/projects"><i class="material-icons">description</i>Projects</a></li>
        <li><a class="waves-effect" href="/categories"><i class="material-icons">sort</i>Categories</a></li>
        <li><a class="waves-effect" href="/tags"><i class="material-icons">label</i>Tags</a></li>
        <li><a class="waves-effect" href="http://khoablogs.github.io" target="_blank"><i class="material-icons">rss_feed</i>Beta</a></li>
        <li><div class="divider"></div></li>
        <li><a class="waves-effect" href="/about"><i class="material-icons">person</i>About</a></li>
        <li><a class="waves-effect" href="/contact"><i class="material-icons">email</i>Contact</a></li>
      </ul>
    </header>
    <main>

<div class="container">
  <div id="page-info">
  <h3></h3>
</div>
<div class="row">
  <h5 id="23-the-gaussian-distribution"><strong>2.3. The Gaussian Distribution</strong></h5>

<ul>
  <li>
    <p>The Gaussian, also known as the normal distribution, is a widely used model for the distribution of <em>continuous variables</em>. For single variable $x$, the Gaussian distribution can be written in the form:
\(\mathcal{N}(x|\mu,\sigma^2)=\frac{1}{(2\pi\sigma^2)^{1/2}}\exp{\{-\frac{1}{2\sigma^2}(x-\mu)^2\}}\tag1\)</p>

    <p>where $\mu,\sigma^2$ are the mean and the variance respectively.</p>

    <p>
    <img src="https://raw.githubusercontent.com/khoatranrb/Img4Md/master/B/MLPR5/0.png" />
    <center><b>Figure 1: 1-dimensional Gaussian distribution</b></center>
    <center><i>Source: https://www.researchgate.net/figure/Gaussian-bell-function-normal-distribution-N-0-s-2-with-varying-variance-s-2-For_fig1_334535945</i></center>
</p>
  </li>
  <li>
    <p>For $D-$dimensional vector $\mathbf{x}$, the <em>multivariate Gaussian distribution</em> takes the form:
\(\mathcal{N}(\mathbf{x}|\vec\mu,\Sigma)=\frac{1}{(2\pi)^{D/2}|\Sigma|^{1/2}}\exp{\{-\frac{1}{2}(\mathbf{x}-\vec\mu)^\top\Sigma^{-1}(\mathbf{x}-\vec\mu)\}}\tag2\)
where the mean and the covariance matrix was mentioned in <a href="https://khoablog.github.io/2020/04/17/ml&amp;pr-2" style="color:green">ML&amp;PR_2</a>.</p>
  </li>
</ul>

<p>
         <img src="https://raw.githubusercontent.com/khoatranrb/Img4Md/master/B/MLPR5/3.png" />
    <center><b>Figure 2: 2-dimensional Gaussian distribution</b></center>
    <center><i>Source: http://rinterested.github.io/statistics/multivariate_gaussian.html</i></center>
</p>

<ul>
  <li>
    <p>The Gaussian distribution arises in many different context. For example, Figure 3 plots the mean of $N$ uniformly distributed numbers for various values of $N$:</p>

    <p>
    <img src="https://raw.githubusercontent.com/khoatranrb/Img4Md/master/B/MLPR5/1.png" />
    <center><b>Figure 3</b></center>
    <center><i>Source: Pattern Recognition and Machine Learning | C.M.Bishop</i></center>
</p>
  </li>
  <li>
    <p>Let consider the geometrical form of the Gaussian distribution:
\(\Delta^2=(\mathbf{x-\vec\mu})^\top\Sigma^{-1}(\mathbf{x-\vec\mu})\tag3\)
The $\Delta$ called <em>Mahalanobis distance</em> from $\mathbf{x}$ to $\vec\mu$. In <em>Euclidean distance</em>, $\Sigma$ is identity matrix.</p>
  </li>
  <li>
    <p>We know that $\Sigma$ is a symmetric matrix. So, it has only real eigenvalues, specifically $D$ eigenvalues $\lambda_1,…\lambda_D$:
\(\Sigma\mathbf{u}_i=\lambda_i\mathbf{u}_i\tag4\)
where $\mathbf{u}_i$ is a eigenvector corresponding to $\lambda_i$. The eigenvectors are chosen to form an orthogonal set such that:
\(\mathbf{u}_i^\top\mathbf{u}_j=\begin{cases}1 \ \ \ \text{if} \ i=j \\ 0 \ \ \ \text{otherwise}\end{cases}\tag5\)</p>
  </li>
  <li>
    <p>We can rewrite $\Sigma$ in the form:
\(\Sigma=\sum_{i=1}^D\lambda_i\mathbf{u}_i\mathbf{u}_i^\top\tag6\)
Similarity, we have:
\(\Sigma^{-1}=\sum_{i=1}^D\frac{1}{\lambda_i}\mathbf{u}_i\mathbf{u}_i^\top\tag7\)</p>
  </li>
  <li>
    <p>From $(7)$, $(3)$ becomes:
\(\begin{align}
\Delta^2&amp;=\sum_{i=1}^D\frac{1}{\lambda_i}(\mathbf{x-\vec\mu})^\top\mathbf{u}_i\mathbf{u}_i^\top(\mathbf{x-\vec\mu})\tag8\\
&amp;=\sum_{i=1}^D\frac{1}{\lambda_i}[\mathbf{u}_i^\top(\mathbf{x-\vec\mu})]^\top\mathbf{u}_i^\top(\mathbf{x-\vec\mu})\tag9\\
&amp;=\sum_{i=1}^D(\frac{\mathbf{u}_i^\top(\mathbf{x-\vec\mu})}{\lambda_i^{1/2}})^2\tag{10}\\
&amp;=\sum_{i=1}^D(\frac{\mathbf{y}_i}{\lambda_i^{1/2}})^2\tag{11}
\end{align}\)
where $\mathbf{y}_i=\mathbf{u}_i^\top(\mathbf{x}-\vec\mu)$.</p>

    <p>$(9)=(10)$ because $\mathbf{u}_i^\top(\mathbf{x-\vec\mu})\in\mathcal{R}^1$ so $[\mathbf{u}_i^\top(\mathbf{x-\vec\mu})]^\top\mathbf{u}_i^\top(\mathbf{x-\vec\mu})=[\mathbf{u}_i^\top(\mathbf{x-\vec\mu})]^2$.</p>
  </li>
  <li>
    <p>Forming $\mathbf{U}=[\mathbf{u}_1 \ … \ \mathbf{u}_D]^\top$, we obtain:
\(\mathbf{y}=[\mathbf{y}_1 \ ... \ \mathbf{y}_D]^\top=\mathbf{U}(\mathbf{x}-\vec\mu)\tag{12}\)
Note that: $\mathbf{U}$ is a orthogonal matrix.</p>

    <p>If all of eigenvalues $\lambda_i$ are positive, these surfaces represent ellipsoids with center $\vec\mu$ and their axes oriented along $\mathbf{u}_i$. We see that $\mathbf{y}_i$ is a vector $\mathbf{x}-\vec\mu$ projected into $\mathbf{u}_i$ coordinate which scaling factor $\lambda_i^{1/2}$.</p>

    <p>
    <img src="https://raw.githubusercontent.com/khoatranrb/Img4Md/master/B/MLPR5/4.png" />
    <center><b>Figure 4</b></center>
    <center><i>Source: Pattern Recognition and Machine Learning | C.M.Bishop</i></center>
</p>
  </li>
  <li>
    <p>Also, we have:
\(|\Sigma|=\prod_{i=1}^D\lambda_i\tag{13*}\)</p>
  </li>
  <li>
    <p>We now define
\(\mathbf{J}=\frac{\partial \mathbf{x}}{\mathbf{\partial y}}=\mathbf{U}^\top\tag{14}\)
Then
\(|\mathbf{J}|^2=|\mathbf{U^\top}|^2=1\tag{15}\)</p>
  </li>
  <li>
    <p>Thus, in the $\mathbf{y}$ coordinate system, the Gaussian distribution takes the form:
\(p(\mathbf{y})=p(\mathbf{x})|\mathbf{J}|=\prod_{i=1}^D\frac{1}{(2\pi\lambda_i)^{1/2}}\exp{\{-\frac{\mathbf{y}_i^2}{2\lambda_i}\}}\tag{16}\)
also
\(\int p(\mathbf{y})d\mathbf{y}=\prod_{i=1}^D\int_{-\infty}^{\infty}\frac{1}{(2\pi\lambda_i)^{1/2}}\exp{\{-\frac{\mathbf{y}_i^2}{2\lambda_i}\}}\text{d}\mathbf{y}_i=1\tag{17}\)</p>
  </li>
  <li>
    <p>From $(2)$ we have:
\(\begin{align}
&amp;\frac{1}{(2\pi)^{D/2}|\Sigma|^{1/2}}\int\exp{\{-\frac{1}{2}(\mathbf{x}-\vec\mu)^\top\Sigma^{-1}(\mathbf{x}-\vec\mu)\}}\text{d}\mathbf{x}\\
&amp;=\frac{1}{(2\pi)^{D/2}|\Sigma|^{1/2}}\int\exp{\{-\frac{1}{2}\mathbf{z}^\top\Sigma^{-1}\mathbf{z}\}}\text{d}\mathbf{z}=1\tag{18}
\end{align}\)
where $\mathbf{z=x-\vec\mu}$.</p>

    <p>So:
\(\begin{align}
\mathbb{E}[\mathbf{x}]&amp;=\frac{1}{(2\pi)^{D/2}|\Sigma|^{1/2}}\int\exp{\{-\frac{1}{2}(\mathbf{x}-\vec\mu)^\top\Sigma^{-1}(\mathbf{x}-\vec\mu)\}}\mathbf{x}\text{d}\mathbf{x}\\
&amp;=\frac{1}{(2\pi)^{D/2}|\Sigma|^{1/2}}\int\exp{\{-\frac{1}{2}\mathbf{z}^\top\Sigma^{-1}\mathbf{z}\}}(\mathbf{z+\vec\mu})\text{d}\mathbf{z}\tag{19}\\
&amp;=\frac{1}{(2\pi)^{D/2}|\Sigma|^{1/2}}(\int\exp{\{-\frac{1}{2}\mathbf{z}^\top\Sigma^{-1}\mathbf{z}\}}\mathbf{z}\text{d}\mathbf{z}+\int\exp{\{-\frac{1}{2}\mathbf{z}^\top\Sigma^{-1}\mathbf{z}\}}\vec\mu\text{d}\mathbf{z})\tag{20}\\
&amp;=\frac{1}{(2\pi)^{D/2}|\Sigma|^{1/2}}(\int\mathbb{A}\text{d}\mathbf{z}+\vec\mu\int\mathbb{B}\text{d}\mathbf{z})\tag{21}
\end{align}\)
where $\mathbb{A}=\exp{{-\frac{1}{2}\mathbf{z}^\top\Sigma^{-1}\mathbf{z}}}\mathbf{z}$ and $\mathbb{B}=\exp{{-\frac{1}{2}\mathbf{z}^\top\Sigma^{-1}\mathbf{z}}}$.</p>

    <p>We see that $\mathbb{A}$ is an odd function, then $\displaystyle\int\mathbb{A}\text{d}\mathbf{z}=0$.</p>

    <table>
      <tbody>
        <tr>
          <td>From $(18)$ and $(21)$, we have $\vec\mu\frac{1}{(2\pi)^{D/2}</td>
          <td>\Sigma</td>
          <td>^{1/2}}\displaystyle\int\mathbb{B}\text{d}\mathbf{z}=\vec\mu$.</td>
        </tr>
      </tbody>
    </table>

    <p>Therefore,
\(\mathbb{E}[\mathbf{x}]=\vec\mu\tag{22}\)</p>
  </li>
  <li>
    <p>Let consider second order moments of the Gaussian - $\mathbb{E}[\mathbf{xx^\top}]$:
\(\begin{align}
\mathbb{E}[\mathbf{xx^\top}]&amp;=\frac{1}{(2\pi)^{D/2}\Sigma^{1/2}}\int\exp{\{-\frac{1}{2}(\mathbf{x-\vec\mu)}^\top\Sigma^{-1}\mathbf{(x-\vec\mu)}\}\mathbf{xx^\top}\text{d}\mathbf{x}}\tag{23}\\
&amp;=\frac{1}{(2\pi)^{D/2}\Sigma^{1/2}}\int\exp\{-\frac{1}{2}\mathbf{z^\top}\Sigma^{-1}\mathbf{z}\}(\mathbf{z+\vec\mu})(\mathbf{z+\vec\mu})^\top\text{d}\mathbf{z}\tag{24}\\
&amp;=\frac{1}{(2\pi)^{D/2}\Sigma^{1/2}}(\int\exp\{-\frac{1}{2}\mathbf{z^\top}\Sigma^{-1}\mathbf{z}\}\mathbf{zz^\top}\text{d}\mathbf{z}+\int\exp\{-\frac{1}{2}\mathbf{z^\top}\Sigma^{-1}\mathbf{z}\}\mathbf{\vec\mu\vec\mu^\top}\text{d}\mathbf{z})\tag{25}
\end{align}\)
$(24)=(25)$ because $\exp{-\frac{1}{2}\mathbf{z^\top}\Sigma^{-1}\mathbf{z}}(\mathbf{z\vec\mu^\top+\vec\mu z^\top})$ is an odd function so the integral is equal zero.</p>

    <p>We now consider:
\(\begin{align}
&amp;\frac{1}{(2\pi)^{D/2}\Sigma^{1/2}}\int\exp\{-\frac{1}{2}\mathbf{z^\top}\Sigma^{-1}\mathbf{z}\}\mathbf{zz^\top}\text{d}\mathbf{z}\\
&amp;=\frac{1}{(2\pi)^{D/2}\Sigma^{1/2}}\sum_{i=1}^D\sum_{j=1}^D\mathbf{u}_i\mathbf{u}_j^\top\int\exp\{-\sum_{k=1}^D\frac{y_k^2}{2\lambda_k}\}y_iy_j\text{d}\mathbf{y}\tag{26}\\
&amp;=\frac{1}{(2\pi)^{D/2}\Sigma^{1/2}}\sum_{i=1}^D\mathbf{u}_i\mathbf{u}_i^\top\int\exp\{-\sum_{k=1}^D\frac{y_k^2}{2\lambda_k}\}y_i^2\text{d}\mathbf{y}\tag{27}\\
&amp;=\frac{1}{(2\pi)^{D/2}\prod_{j=1}^D\lambda_j^{1/2}}\sum_{i=1}^D\mathbf{u}_i\mathbf{u}_i^\top\int\exp\{-\sum_{k=1}^D\frac{y_k^2}{2\lambda_k}\}y_i^2\text{d}\mathbf{y}\tag{28}\\
&amp;=\sum_{i=1}^D\mathbf{u}_i\mathbf{u}_i^\top\int y_i^2\prod_{j=1}^D\frac{1}{(2\pi\lambda_j)^{1/2}}\exp\{-\frac{y_j^2}{2\lambda_j}\}\text{d}y_j\tag{29}\\
&amp;=\sum_{i=1}^D\mathbf{u}_i\mathbf{u}_i^\top(\int\frac{1}{(2\pi\lambda_1)^{1/2}}\exp\{-\frac{y_1^2}{2\lambda_1}\}\text{d}y_1\times...\times \int\frac{1}{(2\pi\lambda_i)^{1/2}}\exp\{-\frac{y_i^2}{2\lambda_i}\}y_i^2\text{d}y_i\times...\times \int\frac{1}{(2\pi\lambda_D)^{1/2}}\exp\{-\frac{y_D^2}{2\lambda_D}\}\text{d}y_D)\tag{30}\\
&amp;=\sum_{i=1}^D\mathbf{u}_i\mathbf{u}_i^\top(1\times...\times\lambda_i\times...\times1)=\sum_{i=1}^D\mathbf{u}_i\mathbf{u}_i^\top\lambda_i=\Sigma\tag{31}
\end{align}\)</p>

    <ul>
      <li>
        <p>We have $(26) $ because from $(12)$ we obtain:
\(\mathbf{z}=\mathbf{U}^{-1}\mathbf{y}=\mathbf{U^\top y}=\sum_{i=1}^D\mathbf{u}_iy_i\tag{32}\)</p>
      </li>
      <li>
        <p>$(26)=(27 )$ because $\mathbf{U}$ is an orthogonal matrix so $\mathbf{u}_i\mathbf{u}_j^\top=\mathbf{0} \ \forall i\ne j$.</p>
      </li>
      <li>
        <p>$(27)=(28)$ because of $(13)$.</p>
      </li>
      <li>
        <p>We have $(28)=(29)$ from $(16)(17)$, have $(31)$ from $(6)$.</p>
      </li>
      <li>
        <p>$(29)=(30)$ because from $(1)$ we have
\(\int\frac{1}{(2\pi\sigma^2)^{1/2}}\exp{\{-\frac{1}{2\sigma^2}(x-\mu)^2\}}\text{d}x=1\tag{33*}\)</p>
      </li>
    </ul>

    <p>Thus 
\(\mathbb{E}[\mathbf{xx^\top}]=\vec\mu\vec\mu^\top+\Sigma\tag{34}\)</p>
  </li>
</ul>

<h5 id="appendix-"><strong>Appendix (*)</strong></h5>

<ol>
  <li>
    <p>The product of the eigenvalues is the determinant of a matrix:
\(|\Sigma|=\prod_i\lambda_i\tag{13*}\)
<strong>Proof:</strong></p>

    <ul>
      <li>
        <p>First, we analysis $\Sigma$ to:
\(\Sigma=\mathbf{P}\text{diag}(\lambda_1,...,\lambda_n)\mathbf{P}^{-1}\tag{35}\)</p>
      </li>
      <li>
        <p>Use the property of determinant $|\mathbf{AB}|=|\mathbf{BA}|$, we have:
\(\begin{align}
|\Sigma|&amp;=|\mathbf{P}\text{diag}(\lambda_1,...,\lambda_n)\mathbf{P}^{-1}|\tag{36}\\
&amp;=|\text{diag}(\lambda_1,...,\lambda_n)\mathbf{P}^{-1}\mathbf{P}|\tag{37}\\
&amp;=|\text{diag}(\lambda_1,...,\lambda_n)\mathbf{I}|\tag{38}\\
&amp;=\prod_i\lambda_i
\end{align}\)</p>
      </li>
    </ul>
  </li>
  <li>
    <p>The integral of Gaussian is 1:
\(\int\frac{1}{(2\pi\sigma^2)^{1/2}}\exp{\{-\frac{1}{2\sigma^2}(x-\mu)^2\}}\text{d}x=1\tag{33*}\)
We have to prove
\(\int\exp\{-\frac{(x-\mu)^2}{2\sigma^2}\}\text{d}x=(2\pi\sigma^2)^{1/2}\tag{39}\)
<strong>Proof:</strong>
\(\begin{align}
\int\exp\{-\frac{(x-\mu)^2}{2\sigma^2}\}\text{d}x&amp;=\int\exp\{-\frac{x^2}{2\sigma^2}\}\text{d}x\tag{40}\\
&amp;=\int\exp\{-(\frac{x}{\sqrt{2\sigma^2}})^2\}\text{d}x\tag{41}\\
&amp;=(2\sigma^2)^{1/2}\int\exp\{-x^2\}\text{d}x\tag{42}
\end{align}\)</p>

    <ul>
      <li>We now prove $\displaystyle\int\exp{-x^2}\text{d}x=\pi^{1/2}$. We have:
\(\begin{align}
(\int_{-\infty}^{+\infty}e^{-x^2}\text{d}x)^2&amp;=\int_{-\infty}^{+\infty}e^{-x^2}\text{d}x\int_{-\infty}^{+\infty}e^{-y^2}\text{d}y\tag{43}\\
&amp;=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}e^{-(x^2+y^2)}\text{d}x\text{d}y\tag{44}
\end{align}\)
Set $x=r\cos(\theta)$, $y=r\sin(\theta)$, we have:
\(\begin{align}
(43)&amp;=\int_0^{2\pi}\int_0^{+\infty}e^{-r^2}r \ \text{d}r \text{d}\theta\tag{45}\\
&amp;=\int_0^{2\pi}\frac{1}{2}\text{d}\theta=\pi\tag{46}
\end{align}\)
So, we have just prove
\(\displaystyle\int\exp\{-x^2\}\text{d}x=\pi^{1/2}\tag{47}\)
Then, $(33^*)$ was proved.</li>
    </ul>
  </li>
</ol>

<h5 id="reference"><strong>Reference:</strong></h5>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>2.3</td>
          <td>Pattern Recognition and Machine Learning</td>
          <td>C.M.Bishop.</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li><a href="http://www.umich.edu/~chem461/Gaussian%20Integrals.pdf" style="color:green">Gaussian integrals | University of Michigan. </a></li>
</ul>

</div>
</div>

    </main>
    <footer class="page-footer teal">
      <div class="container">
        <div class="row">
          <div class="col s12">
            <img src="/assets/res/logo.png" alt="logo"/>
            <p class="grey-text text-lighten-4">Science Blog!
</p>
          </div>
        </div>
      </div>
      <div class="footer-copyright">
        <div class="container">
          &#xA9; 2021 Khoa Blog. All rights reserved. Powered by <a href="https://github.com/khoablog/khoablog.github.io">Khoa</a>.
        </div>
      </div>
    </footer>
    <script src="//code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/materialize/0.99.0/js/materialize.min.js"></script>
    
    
    
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})
      (window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-96359860-1', 'auto');
      ga('send', 'pageview');
    </script>
    
    <script src="/assets/js/main.js"></script>
  </body>
</html>