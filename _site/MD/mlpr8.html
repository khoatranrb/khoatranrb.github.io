<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      
      Khoa Blog
      
    </title>
    <link rel="shortcut icon" type="image/x-icon" href="/assets/res/favicon.ico">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/materialize/0.99.0/css/materialize.min.css">
    <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="/assets/css/main.css">
    
    
    <link rel="stylesheet" href="/assets/css/page.css">
    
    
    
    <link rel="stylesheet" href="/assets/css/syntax.css">
    <link rel="alternate" title="Beta" href="http://khoablogs.github.io">
    <link rel="sitemap" type="application/xml" title="Sitemap" href="/sitemap.xml">
    <!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Khoa Blog" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Science Blog!" />
<meta property="og:description" content="Science Blog!" />
<link rel="canonical" href="http://localhost:4000/MD/mlpr8" />
<meta property="og:url" content="http://localhost:4000/MD/mlpr8" />
<meta property="og:site_name" content="Khoa Blog" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Khoa Blog" />
<meta name="google-site-verification" content="UA-96359860-1" />
<script type="application/ld+json">
{"@type":"WebPage","url":"http://localhost:4000/MD/mlpr8","headline":"Khoa Blog","description":"Science Blog!","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>
  <body>
    <header>
      <nav class="top-nav teal">
        <div class="nav-wrapper">
          <div class="container">
            <a class="page-title" href="/">Khoa Blog</a>
          </div>
        </div>
      </nav>
      <div class="container">
        <a href="#" data-activates="slide-out" class="button-collapse top-nav full hide-on-large-only">
          <i class="material-icons">menu</i>
        </a>
      </div>
      <ul id="slide-out" class="side-nav fixed">
        <li>
          <div class="userView">
            <div class="background"></div>
            <a href="https://github.com/khoatranrb" target="_blank"><img class="circle z-depth-2" src="/assets/res/user.png"></a>
            <span class="white-text name">Khoa Tran</span>
            <span class="white-text email">khoatranrb@gmail.com</span>
          </div>
        </li>
        <li><a class="waves-effect" href="/"><i class="material-icons">home</i>Home</a></li>
        <li><a class="waves-effect" href="/projects"><i class="material-icons">description</i>Projects</a></li>
        <li><a class="waves-effect" href="/categories"><i class="material-icons">sort</i>Categories</a></li>
        <li><a class="waves-effect" href="/tags"><i class="material-icons">label</i>Tags</a></li>
        <li><a class="waves-effect" href="http://khoablogs.github.io" target="_blank"><i class="material-icons">rss_feed</i>Beta</a></li>
        <li><div class="divider"></div></li>
        <li><a class="waves-effect" href="/about"><i class="material-icons">person</i>About</a></li>
        <li><a class="waves-effect" href="/contact"><i class="material-icons">email</i>Contact</a></li>
      </ul>
    </header>
    <main>

<div class="container">
  <div id="page-info">
  <h3></h3>
</div>
<div class="row">
  <ul>
  <li>
    <p>Consider two sets of variables are jointly Gaussian, then, the conditional distribution of one set conditioned on the other is again Gaussian.</p>
  </li>
  <li>
    <p>Suppose $\mathbf{x}$ is a $D$-dimensional vector with Gaussian distribution $\mathcal{N(\mathbf{x|\mu,\Sigma})}$. We split $\mathbf{x}$ into two parts: $\mathbf{x}_a$ and $\mathbf{x}_b$ where $\mathbf{x}_a$ takes first $M$ components of $\mathbf{x}$ and $\mathbf{x}_b$ takes $D-M$ remaining components.
\(\mathbf{x}=
\begin{pmatrix}
\mathbf{x}_a\\\mathbf{x}_b\tag1
\end{pmatrix}.\)</p>
  </li>
  <li>
    <p>We now define the mean of $\mathbf{x}$:
\(\mathbf{\mu}=
\begin{pmatrix}
\mathbf{\mu}_a\\\mathbf{\mu}_b\tag2
\end{pmatrix}\)
and the covariance matrix of $\mathbf{x}$:
\(\mathbf{\Sigma}=
\begin{pmatrix}
\mathbf{\Sigma}_{aa}&amp;\mathbf{\Sigma}_{ab}\\\mathbf{\Sigma}_{ba}&amp;\mathbf{\Sigma}_{bb}\tag3.
\end{pmatrix}.\)
In there, $\mathbf{\Sigma}$, $\mathbf{\Sigma}<em>{aa}$ and $\mathbf{\Sigma}</em>{bb}$ are symmetric and $\mathbf{\Sigma}<em>{ab}=\mathbf{\Sigma}</em>{ba}^\top$.</p>
  </li>
  <li>
    <p>We now define <em>precision matrix</em> takes a form:
\(\mathbf{\Lambda} = \mathbf{\Sigma}^{-1}\tag4.\)</p>

    <p>Because $\mathbf{\Sigma}$ is symmetric, $\mathbf{\Lambda}$ also is symmetric $(\text{Appendix1})$. So we can rewrite this matrix as follows:
\(\mathbf{\Lambda}=
\begin{pmatrix}
\mathbf{\Lambda}_{aa}&amp;\mathbf{\Lambda}_{ab}\\
\mathbf{\Lambda}_{ba}&amp;\mathbf{\Lambda}_{bb}.
\end{pmatrix}\tag5\)
where $\mathbf{\Lambda}$, $\mathbf{\Lambda}<em>{aa}$ and $\mathbf{\Lambda}</em>{bb}$ are symmetric and $\mathbf{\Lambda}<em>{ab}=\mathbf{\Lambda}</em>{ba}^\top$.</p>

    <p><strong>Note that:</strong> $\mathbf{\Lambda}<em>{aa}$ is not the invert of $\mathbf{\Sigma}</em>{aa}$, similar to $\mathbf{\Lambda}_{bb}$. We will discuss about it later.</p>
  </li>
  <li>
    <p>Now we discuss about the conditional distribution $p(\mathbf{x}_a|\mathbf{x}_b)$, consider $\mathbf{x}_b$ is the observed value. We start form the joint distribution $p(\mathbf{x})=p(\mathbf{x}_a,\mathbf{x}_b)$. To explore it, we consider the quadratic form of Gaussian distribution (as mentioned in <a href="https://khoatranrb.github.io/2020/11/30/ml&amp;pr-8" style="color:green">MLPR8</a>) combine with the partitioning $(3)$ and $(5)$:
\(\begin{align}
-\frac{1}{2}(\mathbf{x-\mu})^\top\mathbf{\Sigma}^{-1}(\mathbf{x}-\mu)&amp;=-\frac{1}{2}(\mathbf{x}_a-\mu_a)^\top\mathbf{\Lambda}_{aa}(\mathbf{x}_a-\mu_a)\\
&amp;\ \ \ \ -\frac{1}{2}(\mathbf{x}_a-\mu_a)^\top\mathbf{\Lambda}_{ab}(\mathbf{x}_b-\mu_b)\\
&amp;\ \ \ \ -\frac{1}{2}(\mathbf{x}_b-\mu_b)^\top\mathbf{\Lambda}_{ba}(\mathbf{x}_a-\mu_a)\\
&amp;\ \ \ \ -\frac{1}{2}(\mathbf{x}_b-\mu_b)^\top\mathbf{\Lambda}_{bb}(\mathbf{x}_b-\mu_b).\tag6\\
\end{align}\)
The $(6)$ is the function of $\mathbf{x}_a$, we can use this property
\(\begin{align}
-\frac{1}{2}(\mathbf{a}-\mu)^\top\mathbf{\Sigma}^{-1}(\mathbf{a}-\mu)&amp;=-\frac{1}{2}\mathbf{a}^\top\mathbf{\Sigma}^{-1}\mathbf{a}\\
&amp;\ \ \ \ +\frac{1}{2}\mathbf{a^\top\Sigma}^{-1}\mu+\frac{1}{2}\mathbf{\mu^\top\Sigma}^{-1}\mathbf{a}\\
&amp;\ \ \ \ \ -\frac{1}{2}\mu^\top\mathbf{\Sigma}^{-1}\mu\tag7\\
&amp;=\frac{1}{2}\mathbf{a}^\top\mathbf{\Sigma}^{-1}\mathbf{a} +\mathbf{a^\top\Sigma}^{-1}\mu-\frac{1}{2}\mu^\top\mathbf{\Sigma}^{-1}\mu\tag8\\
\end{align}\)
(because of $\mathbf{\Sigma}^{-1}$ is symmetric then $\mathbf{a^\top\Sigma}^{-1}\mu=\mathbf{\mu^\top\Sigma}^{-1}\mathbf{a}$)</p>

    <p>to rewrite it by:
\(\begin{align}
-\frac{1}{2}(\mathbf{x-\mu})^\top\mathbf{\Sigma}^{-1}(\mathbf{x}-\mu)&amp;=-\frac{1}{2}\mathbf{x}_a^\top\mathbf{\Lambda}_{aa} \mathbf{x}_a+\mathbf{x}_a^\top\mathbf{\Lambda}_{aa}\mu_a-\frac{1}{2}\mu_a^\top\mathbf{\Lambda}_{aa}\mu_a\\
&amp;\ \ \ \ \ -\frac{1}{2}\mathbf{x}_a^\top\mathbf{\Lambda}_{ab} \mathbf{x}_b+\frac{1}{2}\mathbf{x}_a^\top\mathbf{\Lambda}_{ab}\mu_b+\frac{1}{2}\mathbf{\mu}_a^\top\mathbf{\Lambda}_{ab}\mathbf{x}_b-\frac{1}{2}\mu_a^\top\mathbf{\Lambda}_{ab}\mu_b\\
&amp;\ \ \ \ \ -\frac{1}{2}\mathbf{x}_b^\top\mathbf{\Lambda}_{ba} \mathbf{x}_a+\frac{1}{2}\mathbf{x}_b^\top\mathbf{\Lambda}_{ba}\mu_a+\frac{1}{2}\mathbf{\mu}_b^\top\mathbf{\Lambda}_{ba}\mathbf{x}_a-\frac{1}{2}\mu_b^\top\mathbf{\Lambda}_{ba}\mu_a\\
&amp;\ \ \ \ \ -\frac{1}{2}(\mathbf{x}_b-\mu_b)^\top\mathbf{\Lambda}_{bb}(\mathbf{x}_b-\mu_b)\tag9\\
&amp;=-\frac{1}{2}\mathbf{x}_a^\top\mathbf{\Lambda}_{aa} \mathbf{x}_a+\mathbf{x}_a^\top\{\mathbf{\Lambda}_{aa}\mu_a-\mathbf{\Lambda}_{ab}(\mathbf{x}_b-\mu_b)\}+C\tag{10}
\end{align}\)
where
\(C=-\frac{1}{2}\mu_a^\top\mathbf{\Lambda}_{aa}\mu_a+\mu_a^\top\mathbf{\Lambda}_{ab}(\mathbf{x}_b-\mu_b)-\frac{1}{2}(\mathbf{x}_b-\mu_b)^\top\mathbf{\Lambda}_{bb}(\mathbf{x}_b-\mu_b).\tag{11}\)
We obtain $(10)$ from $(9)$ by  property $\mathbf{\Lambda}<em>{ab}=\mathbf{\Lambda}</em>{ba}^\top$. We see this is again a quadratic form with $C$ is independent of $\mathbf{x}_a$. So the condition distribution $p(\mathbf{x}_a|\mathbf{x}_b)$ will be Gaussian.</p>
  </li>
  <li>
    <p>We use the quadratic form to determine mean and covariance of conditional distribution, denoted as $\mu_{a|b}$ and $\mathbf{\Sigma}_{a|b}$, respectively. Consider the second order of $\mathbf{x}_a$:
\(-\frac{1}{2}\mathbf{x}_a^\top\mathbf{\Lambda}_{aa}\mathbf{x}_a\tag{12}\)
we can inference the covariance of $p(\mathbf{x}_a|\mathbf{x}_b)$ is:
\(\mathbf{\Sigma}_{a|b}=\mathbf{\Lambda}_{aa}^{-1}\tag{13}.\)
Next, we consider the first order of $\mathbf{x}_a$:
\(\mathbf{x}_a\{\mathbf{\Lambda}_{aa}\mu_a-\mathbf{\Lambda}_{ab}(\mathbf{x}_b-\mu_b)\}\tag{14}\)
we can obtain:
\(\begin{align}
\mu_{a|b}&amp;=\mathbf{\Sigma}_{a|b}\{\mathbf{\Lambda}_{aa}\mu_a-\mathbf{\Lambda}_{ab}(\mathbf{x}_b-\mu_b)\}\\
&amp;=\mu_a-\mathbf{\Lambda}_{aa}^{-1}\mathbf{\Lambda}_{ab}(\mathbf{x}_b-\mu_b).\tag{15}
\end{align}\)</p>
  </li>
  <li>
    <p>Next, we determine each path of $\mathbf{\Lambda}$ based on the following lemma:
\(\begin{pmatrix}
\mathbf{A}&amp;\mathbf{B}\\\mathbf{C}&amp;\mathbf{D}
\end{pmatrix}^{-1}=\begin{pmatrix}
\mathbf{M}&amp;-\mathbf{MBD}^{-1}\\-\mathbf{D}^{-1}\mathbf{CM}&amp;\mathbf{D}^{-1}+\mathbf{D}^{-1}\mathbf{CMBD}^{-1}
\end{pmatrix}\tag{16}\)
where $\mathbf{M}$ is the <em>Schur complement</em> $(\text{Appendix2})$ of $\mathbf{D}$ and $\mathbf{M}^{-1}$ is the <em>Schur complement</em> of $\mathbf{A}$, defined as:
\(\mathbf{M}=(\mathbf{A}-\mathbf{BD}^{-1}\mathbf{C})^{-1}\tag{17}.\)</p>
  </li>
  <li>
    <p>Back to $(4)$ we have:
\(\begin{pmatrix}
\mathbf{\Sigma}_{aa}&amp;\mathbf{\Sigma}_{ab}\\\mathbf{\Sigma}_{ba}&amp;\mathbf{\Sigma}_{bb}
\end{pmatrix}^{-1}=\begin{pmatrix}
\mathbf{\Lambda}_{aa}&amp;\mathbf{\Lambda}_{ab}\\
\mathbf{\Lambda}_{ba}&amp;\mathbf{\Lambda}_{bb}
\end{pmatrix}.\tag{18}\)
So:
\(\begin{align}
\mathbf{\Lambda}_{aa}&amp;=(\mathbf{\Sigma}_{aa}-\mathbf{\Sigma}_{ab}\mathbf{\Sigma}_{bb}^{-1}\mathbf{\Sigma}_{ba})^{-1}\tag{19}\\
\mathbf{\Lambda}_{ab}&amp;=-(\mathbf{\Sigma}_{aa}-\mathbf{\Sigma}_{ab}\mathbf{\Sigma}_{bb}^{-1}\mathbf{\Sigma}_{ba})^{-1}\mathbf{\Sigma}_{ab}\mathbf{\Sigma}_{bb}^{-1}\tag{20}
\end{align}.\)</p>
  </li>
</ul>

<h4 id="appendix"><strong>Appendix:</strong></h4>

<ol>
  <li>
    <p>The inverse of a symmetric matrix also symmetric.</p>

    <p><strong>Proof:</strong></p>

    <ul>
      <li>
        <p>Given the inversible and symmetry matrix $A$:
\(\mathbf{A}=\mathbf{A}^\top\tag{21}\)
, we will prove:
\(\mathbf{A}^{-1}=(\mathbf{A}^{-1})^\top\tag{22}.\)</p>
      </li>
      <li>
        <p>First, we have:
\(\mathbf{AA}^{-1}=\mathbf{I}\tag{23}.\)
From $(21)$, we obtain:
\(\mathbf{A}^\top\mathbf{A}^{-1}=\mathbf{I}\tag{24}.\)
Then, use two properties $\mathbf{I}=\mathbf{I}^\top$ and $(\mathbf{A}\mathbf{B})^\top=\mathbf{B}^\top\mathbf{A}^\top$:
\((\mathbf{A}^{-1})^\top \mathbf{A}=\mathbf{I}\tag{25}.\)
Finally, we put $\mathbf{A}^{-1}$ into right side of both:
\(\begin{align}
(\mathbf{A}^{-1})^\top \mathbf{A}\mathbf{A}^{-1}&amp;=\mathbf{I}\mathbf{A}^{-1}\tag{26}\\
(\mathbf{A}^{-1})^\top=\mathbf{A}^{-1}\tag{27}
\end{align}\)
and we are done.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>In order to prove formula $(16)$, we consider the follow equation:
\(\begin{pmatrix}
\mathbf{A}&amp;\mathbf{B}\\\mathbf{C}&amp;\mathbf{D}
\end{pmatrix}
\begin{pmatrix}\mathbf{x}\\\mathbf{y}\end{pmatrix}=\begin{pmatrix}\mathbf{e}\\\mathbf{f}\end{pmatrix}\tag{28}.\)
It equivalent to:
\(\begin{cases}
\mathbf{Ax}+\mathbf{By}=\mathbf{e} \ \ \ (a)\\
\mathbf{Cx}+\mathbf{Dy}=\mathbf{f} \ \ \ (b)
\end{cases}\tag{29}.\)
From the under equation of the formula $(29)$, we obtain:
\(\mathbf{y}=\mathbf{D}^{-1}(\mathbf{f}-\mathbf{Cx})\tag{30}.\)
Replace the $(30)$ into the $(29.a)$, we have:
\(\begin{align}
 \mathbf{Ax}+\mathbf{BD}^{-1}(\mathbf{f-Cx})&amp;=\mathbf{e}\tag{31}\\
 \Leftrightarrow\ \ \ \ \ \ \ \ \ (\mathbf{A}-\mathbf{BD}^{-1}\mathbf{C})\mathbf{x}&amp;=\mathbf{e}-\mathbf{BD}^{-1}\mathbf{f}\tag{32}\\
  \Leftrightarrow\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \mathbf{x}&amp;=(\mathbf{A}-\mathbf{BD}^{-1}\mathbf{C})^{-1}(\mathbf{e}-\mathbf{BD}^{-1}\mathbf{f})\tag{33}\\
    \Leftrightarrow\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \mathbf{x}&amp;=\mathbf{Me}-\mathbf{MBD}^{-1}\mathbf{f}\tag{34}
\end{align}\)
where $\mathbf{M}=(\mathbf{A}-\mathbf{BD}^{-1}\mathbf{C})^{-1}$.</p>

    <p>Replace the $(34)$ into the $(30)$, we calculate the $\mathbf{y}$:
\(\begin{align}
\mathbf{y}&amp;=\mathbf{D}^{-1}[\mathbf{f}-\mathbf{C}(\mathbf{Me}-\mathbf{MBD}^{-1}\mathbf{f})]\tag{35}\\
&amp;=-\mathbf{D}^{-1}\mathbf{CMe}+(\mathbf{D}^{-1}+\mathbf{D}^{-1}\mathbf{MBD}^{-1})\mathbf{f}\tag{36}
\end{align}.\)
From the $(34)$ and the $(36)$, we have:
\(\begin{pmatrix}
\mathbf{x}\\\mathbf{y}
\end{pmatrix}
=\begin{pmatrix}
\mathbf{M}&amp;-\mathbf{MBD}^{-1}\\-\mathbf{D}^{-1}\mathbf{CM}&amp;\mathbf{D}^{-1}+\mathbf{D}^{-1}\mathbf{CMBD}^{-1}
\end{pmatrix}\begin{pmatrix}\mathbf{e}\\\mathbf{f}\end{pmatrix}\tag{37}.\)
As mentioned at $(28)$, we also have:
\(\begin{pmatrix}\mathbf{x}\\\mathbf{y}\end{pmatrix}=\begin{pmatrix}
\mathbf{A}&amp;\mathbf{B}\\\mathbf{C}&amp;\mathbf{D}
\end{pmatrix}^{-1}\begin{pmatrix}\mathbf{e}\\\mathbf{f}\end{pmatrix}\tag{38}.\)
Then, we achieve the goal.</p>
  </li>
</ol>

<h4 id="reference">Reference:</h4>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>2.3.1</td>
          <td>Pattern Recognition and Machine Learning</td>
          <td>C.M. Bishop.</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li><a href="https://www.cis.upenn.edu/~jean/schur-comp.pdf" style="color:green">The Schur Complement and Symmetric PositiveSemidefinite (and Definite) Matrices</a>.</li>
</ul>

</div>
</div>

    </main>
    <footer class="page-footer teal">
      <div class="container">
        <div class="row">
          <div class="col s12">
            <img src="/assets/res/logo.png" alt="logo"/>
            <p class="grey-text text-lighten-4">Science Blog!
</p>
          </div>
        </div>
      </div>
      <div class="footer-copyright">
        <div class="container">
          &#xA9; 2021 Khoa Blog. All rights reserved. Powered by <a href="https://github.com/khoablog/khoablog.github.io">Khoa</a>.
        </div>
      </div>
    </footer>
    <script src="//code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/materialize/0.99.0/js/materialize.min.js"></script>
    
    
    
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})
      (window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-96359860-1', 'auto');
      ga('send', 'pageview');
    </script>
    
    <script src="/assets/js/main.js"></script>
  </body>
</html>